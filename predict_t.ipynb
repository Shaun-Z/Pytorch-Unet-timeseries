{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from utils.data_loading import SGCCDataset\n",
    "import torch\n",
    "from unet import UNet_1D, UNet_1D_N, UNet_1D_L, UNet_1D_NN\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(net,\n",
    "                data,\n",
    "                device,\n",
    "                out_threshold=0.5):\n",
    "    net.eval()\n",
    "    data = data.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(data.shape)\n",
    "        output = net(data).cpu()\n",
    "        # print(output.size())\n",
    "        if net.n_classes > 1:\n",
    "            mask = output.argmax(dim=1)\n",
    "        else:\n",
    "            mask = torch.sigmoid(output) > out_threshold\n",
    "        # print(mask.size())\n",
    "    return mask[0].long().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 'SGCC'\n",
    "dir_checkpoint = Path(f'./checkpoints_pseudo_{id}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zx3_normalized = pd.read_csv(f'./data/{id}_data/data_prepared/zx2_normalized.csv') \n",
    "normal3_normalized = pd.read_csv(f'./data/{id}_data/data_prepared/Normal3_normalized.csv')\n",
    "# Rename the columns of df2 to match df1\n",
    "normal3_normalized.columns = zx3_normalized.columns\n",
    "\n",
    "zy3 = pd.read_csv(f'./data/{id}_data/data_prepared/zy2.csv') \n",
    "normal3_normalized_label = pd.read_csv(f'./data/{id}_data/data_prepared/Normal3_normalized_label.csv')\n",
    "normal3_normalized_label.columns = zy3.columns\n",
    "\n",
    "combined_dfx = pd.concat([zx3_normalized, normal3_normalized], ignore_index=True)#\n",
    "combined_dfy = pd.concat([zy3, normal3_normalized_label], ignore_index=True)#\n",
    "\n",
    "\n",
    "combined_dfx.to_csv(f'./data/{id}_data/data_prepared/combined_dfx.csv', index=False)\n",
    "combined_dfy.to_csv(f'./data/{id}_data/data_prepared/combined_dfy.csv', index=False)\n",
    "\n",
    "\n",
    "# normal3_normalized_sudolabel = pd.read_csv(f'./Normal3_normalized_sudolabel.csv')\n",
    "# normal3_normalized_sudolabel.columns = zy3.columns\n",
    "# combined_dfy_sudo = pd.concat([zy3, normal3_normalized_sudolabel], ignore_index=True)#\n",
    "# combined_dfy_sudo.to_csv('./combined_dfy_sudo.csv', index=False)\n",
    "\n",
    "# normal3_normalized_sudolabel1 = pd.read_csv(f'./Normal3_normalized_sudolabel1.csv')\n",
    "# normal3_normalized_sudolabel1.columns = zy3.columns\n",
    "# combined_dfy_sudo1 = pd.concat([zy3, normal3_normalized_sudolabel1], ignore_index=True)#\n",
    "# combined_dfy_sudo1.to_csv('./combined_dfy_sudo1.csv', index=False)\n",
    "\n",
    "normal3_normalized_pseudolabel2 = pd.read_csv(f'./data/{id}_data/data_prepared/Normal3_normalized_pseudolabel.csv')\n",
    "normal3_normalized_pseudolabel2.columns = zy3.columns\n",
    "combined_dfy_pseudo2 = pd.concat([zy3, normal3_normalized_pseudolabel2], ignore_index=True)#\n",
    "combined_dfy_pseudo2.to_csv(f'./data/{id}_data/data_prepared/combined_dfy_pseudo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dfy_pseudo2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### testing 用的predict_t.py\n",
    "# id = ''\n",
    "##### 改变的地方是：\n",
    "dir_data = Path(f'./data/{id}_data/data_prepared/combined_dfx.csv')\n",
    "# dir_mask = Path('./combined_dfy.csv')\n",
    "dir_mask = Path(f'./data/{id}_data/data_prepared/combined_dfy_pseudo.csv')\n",
    "dataset = SGCCDataset(dir_data, dir_mask)\n",
    "\n",
    "val_percent: float = 0.1\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "data = dataset.data_tensor\n",
    "mask = dataset.mask_tensor\n",
    "\n",
    "data_train = torch.tensor(np.array([train_set[i]['data'] for i in range(len(train_set))]).squeeze())\n",
    "mask_train = torch.tensor(np.array([train_set[i]['mask'] for i in range(len(train_set))]).squeeze())\n",
    "\n",
    "data_val = torch.tensor(np.array([val_set[i]['data'] for i in range(len(val_set))]).squeeze())\n",
    "mask_val = torch.tensor(np.array([val_set[i]['mask'] for i in range(len(val_set))]).squeeze())\n",
    "\n",
    "net = UNet_1D(n_channels=1, n_classes=2, bilinear=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device=device)\n",
    "# state_dict = torch.load('./checkpoints/checkpoint_epoch21.pth', map_location=device)\n",
    "# state_dict = torch.load('./checkpoints_Attack3_pure/checkpoint_epoch20.pth', map_location=device)##old attack 3\n",
    "# state_dict = torch.load('./checkpoints_Attack3_pure/checkpoint_epoch20_combined.pth', map_location=device)##old attack 3+new 3000 normal data\n",
    "# state_dict = torch.load('./checkpoints_Attack3_pure/checkpoint_epoch20_combine_sudo.pth', map_location=device)##old attack 3+new 3000 normal data+sudo label\n",
    "# state_dict = torch.load(f'./checkpoints_sudo_{id}/checkpoint_epoch20.pth', map_location=device)##old attack 3+new \n",
    "# 3000 normal data + pseudo label\n",
    "state_dict = torch.load(f'./checkpoints_pseudo_{id}/checkpoint_epoch20.pth', map_location=device)\n",
    "mask_values = state_dict.pop('mask_values', [0, 1])\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val.shape, mask_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "pred_ts = []\n",
    "for i in range(len(data_val)):\n",
    "    item = data_val[i, :].unsqueeze(0).unsqueeze(0)\n",
    "    print(item.shape)\n",
    "    \n",
    "    mask = predict_data(net=net,\n",
    "                        data=item,\n",
    "                        out_threshold=0.5,\n",
    "                        device=device)\n",
    "\n",
    "    result.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "# result_df.to_csv('result.csv', index=False)\n",
    "zy = pd.DataFrame(np.array(mask_val).astype(int))\n",
    "# zy = pd.read_csv('./combined_dfy.csv')\n",
    "# zy = pd.read_csv(f'./data/{id}_data/data_prepared/combined_dfy_pseudo.csv')\n",
    "# zy = pd.read_csv('.\\Attack3_normalized_label.csv')\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig.suptitle(f'Attack 3')   \n",
    "\n",
    "# Plot the first heatmap\n",
    "sns.heatmap(result_df, ax=ax1)\n",
    "ax1.set_title('Heatmap of prediction')\n",
    "\n",
    "# Plot the second heatmap\n",
    "sns.heatmap(zy, ax=ax2)\n",
    "ax2.set_title('Heatmap of target')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'result{id}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.shape, zy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测窃电，如果连续有7个1，就标记为窃电\n",
    "def mark_continuous_ones(df, threshold=7):\n",
    "    def has_continuous_ones(row):\n",
    "        count = 0\n",
    "        for value in row:\n",
    "            if value == 1:\n",
    "                count += 1\n",
    "                if count >= threshold:\n",
    "                    return True\n",
    "            else:\n",
    "                count = 0\n",
    "        return False\n",
    "\n",
    "    return df.apply(has_continuous_ones, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "result_marked = mark_continuous_ones(result_df)\n",
    "zy_marked = mark_continuous_ones(zy, threshold=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(result_marked, label='Prediction')\n",
    "plt.scatter(np.arange(len(zy_marked)), zy_marked, label='Target', color='red')\n",
    "plt.title('Continuous ones')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(zy_marked, result_marked)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(zy_marked, result_marked)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(zy_marked, result_marked)\n",
    "\n",
    "auc = roc_auc_score(zy_marked, result_marked)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'AUC: {auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
